{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessarry dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from auxFonctions import AminoAcid\n",
    "import fonctionsSupervisedLearning2 as fsl2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redoing fast the Statistical Study in order to get the s values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from a file into a list of entries\n",
    "with open('/Users/mathiasperez/Documents/GitHub/442-2-Protein-cleavage/data/SIG_13.red', 'r') as file:\n",
    "    entries = file.read().split('\\n   ')\n",
    "\n",
    "\n",
    "# Define a function to process each entry in the data file\n",
    "def process_entry(entry):\n",
    "    lines = entry.split('\\n')\n",
    "    protein_id, primary_structure, annotation = lines\n",
    "    return {\n",
    "        'Protein ID': protein_id.split()[1],\n",
    "        'Primary Structure': primary_structure,\n",
    "        'Annotation': annotation\n",
    "    }\n",
    "\n",
    "\n",
    "# Process each entry\n",
    "processed_entries = [process_entry(entry) for entry in entries]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(processed_entries)\n",
    "df['Cleavage_Site'] = df['Annotation'].apply(lambda x: x.find('C'))\n",
    "\n",
    "# Now you can analyze the DataFrame as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average position of the cleavage site:\n",
      "24.04971590909091\n",
      "\n",
      "\n",
      "The extremum position of the cleavage site:\n",
      "13\n",
      "90\n",
      "The distance from cleavage site to the C-terminal part of the amino-sequence:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the position of the cleavage site\n",
    "cleavage_site_position = df['Cleavage_Site']\n",
    "#print(\"Position of the cleavage site:\")\n",
    "#print(cleavage_site_position)\n",
    "print(\"Average position of the cleavage site:\")\n",
    "print(cleavage_site_position.mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"The extremum position of the cleavage site:\")\n",
    "print(cleavage_site_position.min())\n",
    "print(cleavage_site_position.max())\n",
    "\n",
    "print(\"The distance from cleavage site to the C-terminal part of the amino-sequence:\")\n",
    "#there is always 30 amino-acids after the cleavage site\n",
    "print(\"\\n\")\\\n",
    "\n",
    "# with have then p = [13, 1] and q = [1, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the primary structure into a list of amino acids\n",
    "amino_acid_seq = df['Primary Structure'].apply(lambda x: list(x))\n",
    "\n",
    "# Create a DataFrame to store, for each primary structure, the neihborhood of the cleavage site\n",
    "# The neighborhood is defined as the word of length p+q starting p letters before the cleavage site\n",
    "correct_neighborhood = pd.Series(index=amino_acid_seq.index, dtype=str)\n",
    "for i, seq in amino_acid_seq.items():\n",
    "    correct_neighborhood[i] = ''.join(seq[cleavage_site_position[i]-13:cleavage_site_position[i]+2])\n",
    "\n",
    "# for each amino acid in the sequence, replace it with the corresponding AminoAcid object\n",
    "amino_acid_seqB = amino_acid_seq\n",
    "amino_acid_seq = amino_acid_seq.apply(lambda x: [AminoAcid(aa) for aa in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametres de l'Ã©tude\n",
    "p = 13\n",
    "q = 2\n",
    "\n",
    "# Create a DataFrame to store the counts of each amino acid at every position relative to the cleavage site\n",
    "#the cleavage site is between to aminoacids, so cleavage_site_position is the position of the first amino acid after the cleavge site\n",
    "#So i need to create a dataframe with columns from -p to q without 0\n",
    "amino_acid_counts = pd.DataFrame(0, index=AminoAcid.properties.keys(), columns=range(-p, q))\n",
    "amino_acid_freqs = pd.DataFrame(0.0, index=AminoAcid.properties.keys(), columns=range(-p, q)) #f(a,i)\n",
    "amino_acid_pseudo_counts = pd.DataFrame(0, index=AminoAcid.properties.keys(), columns=range(-p, q)) #g(a)\n",
    "amino_acid_s_values = pd.DataFrame(0.0, index=AminoAcid.properties.keys(), columns=range(-p, q)) #s(a,i)\n",
    "\n",
    "\n",
    "# Count the occurrences of each amino acid at every position relative to the cleavage site\n",
    "\n",
    "for i, seq in amino_acid_seq.items():\n",
    "    for j, aa in enumerate(seq):\n",
    "        position = j - cleavage_site_position[i] #position of the amino acid relative to the cleavage site\n",
    "        if position in amino_acid_counts.columns:\n",
    "            amino_acid_counts.loc[aa.code, position] += 1\n",
    "\n",
    "# Add pseudo-counts to avoid zero counts here pseudocount parameter is 1/len(df)\n",
    "amino_acid_pseudo_counts = amino_acid_counts + 1\n",
    "\n",
    "# Print the results\n",
    "#print(\"Occurrences of each amino acid at every position relative to the cleavage site:\")\n",
    "#print(amino_acid_pseudo_counts)\n",
    "\n",
    "# Compute the observed frequency of each amino acid at the relative position (using pseudo-counts)\n",
    "for i in amino_acid_counts.index:\n",
    "    for j in amino_acid_counts.columns:\n",
    "        amino_acid_freqs.loc[i, j] = amino_acid_pseudo_counts.loc[i, j] / len(df)\n",
    "\n",
    "# Compute the general background frequency of each amino acid\n",
    "general_background_frequency = amino_acid_freqs.mean(axis=1)\n",
    "\n",
    "# Compute the s value of each amino acid at every position\n",
    "for i in amino_acid_counts.index:\n",
    "    for j in amino_acid_counts.columns:\n",
    "        amino_acid_s_values.loc[i, j] = math.log(amino_acid_freqs.loc[i, j]) - math.log(general_background_frequency[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store, for each primary structure, the neihborhood of the cleavage site\n",
    "# The neighborhood is defined as the word of length p+q starting p letters before the cleavage site\n",
    "correct_neighborhood = pd.Series()\n",
    "for i, seq in amino_acid_seqB.items():\n",
    "    correct_neighborhood[i] = ''.join(seq[cleavage_site_position[i]-p:cleavage_site_position[i]+q])\n",
    "\n",
    "# Create a DataFrame to store, for each primary structure, a sequence that is not the neighborhood of the cleavage site\n",
    "incorrect_neighborhood = pd.Series()\n",
    "decalage  = [1,2,3,4,5, -1,-2,-3,-4, -5]\n",
    "for i, seq in amino_acid_seqB.items():\n",
    "    dec = np.random.choice(decalage)\n",
    "    dec = 0 if cleavage_site_position[i]-13 - dec < 0 else dec\n",
    "    incorrect_neighborhood[i] = ''.join(seq[cleavage_site_position[i]-p-dec:cleavage_site_position[i]+q-dec])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.302718213229582"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function computing the q-1 score for a given word\n",
    "def q_minus_1_score(word):\n",
    "    return sum([amino_acid_s_values.loc[aa, i-p] for i, aa in enumerate(word)])\n",
    "\n",
    "\n",
    "#A REDEFINIR EN FONCTION DES RESULTATS OBTENUS\n",
    "threshold = 1.5\n",
    "print(threshold)\n",
    "\n",
    "#A simple thresholding (to be tuned) is then enough to define a simple binary classifier.\n",
    "def is_cleavage_neighborhood(score):\n",
    "    return score > threshold\n",
    "\n",
    "q_minus_1_score('AAAAAAAAAAAAAAA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score of the correct neighborhoods:\n",
      "3.2162682210182796\n",
      "\n",
      "\n",
      "Mean score of the incorrect neighborhoods:\n",
      "-1.3301987227426075\n",
      "\n",
      "\n",
      "Standard deviation of the score of the correct neighborhoods:\n",
      "2.5872637135991514\n",
      "Standard deviation of the score of the incorrect neighborhoods:\n",
      "2.7953786959932785\n",
      "Min and max values of the correct neighboorhoods score :\n",
      "-7.931205228611351\n",
      "9.452566054567916\n",
      "Min and max values of the incorrect neighboorhoods score :\n",
      "-10.50805839649406\n",
      "7.898672119113234\n",
      "False negative out of 1408 entries:\n",
      "288\n",
      "False positive out of 1408 entries:\n",
      "207\n"
     ]
    }
   ],
   "source": [
    "# To obtain the score of the correct neighborhoods, we apply the q-1 score function to each neighborhood\n",
    "#correct_neighborhood = correct_neighborhood.apply(lambda x: [AminoAcid(aa) for aa in x])\n",
    "correct_neigboorhood_score = correct_neighborhood.apply(q_minus_1_score)\n",
    "incorrect_neighborhood_score = incorrect_neighborhood.apply(q_minus_1_score)\n",
    "\n",
    "#print(\"Score of the correct neighborhoods:\")\n",
    "#print(correct_neigboorhood_score)\n",
    "#print(\"\\n\")\n",
    "\n",
    "print(\"Mean score of the correct neighborhoods:\")\n",
    "print(correct_neigboorhood_score.mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean score of the incorrect neighborhoods:\")\n",
    "print(incorrect_neighborhood_score.mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Standard deviation of the score of the correct neighborhoods:\")\n",
    "print(correct_neigboorhood_score.std())\n",
    "\n",
    "print(\"Standard deviation of the score of the incorrect neighborhoods:\")\n",
    "print(incorrect_neighborhood_score.std())\n",
    "\n",
    "print(\"Min and max values of the correct neighboorhoods score :\")\n",
    "print(correct_neigboorhood_score.min())\n",
    "print(correct_neigboorhood_score.max())\n",
    "\n",
    "print(\"Min and max values of the incorrect neighboorhoods score :\")\n",
    "print(incorrect_neighborhood_score.min())\n",
    "print(incorrect_neighborhood_score.max())\n",
    "\n",
    "#We now test, with the updated threshold, the performance of the classifier on the training set\n",
    "# Treshold = mean - std\n",
    "false_negatives = correct_neigboorhood_score[correct_neigboorhood_score < threshold].count()\n",
    "print(\"False negative out of \"+str(len(correct_neighborhood))+ \" entries:\")\n",
    "print(false_negatives)\n",
    "\n",
    "false_positives = incorrect_neighborhood_score[incorrect_neighborhood_score > threshold].count()\n",
    "print(\"False positive out of \"+str(len(incorrect_neighborhood))+ \" entries:\")\n",
    "print(false_positives)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILISATION DES RESULTATS POUR CREER LA KERNEL PROBABILISTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_un_caractere(obj):\n",
    "    return isinstance(obj, str) and len(obj) == 1\n",
    "\n",
    "def Phi(x : chr, y : chr, i : int) :\n",
    "    if not(est_un_caractere(x) and est_un_caractere(y)) :\n",
    "        raise ValueError(\"x and y must be single characters\")\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel probabiliste\n",
    "    ### Parameters:\n",
    "    - x : un acide aminÃ© (sous forme de string)\n",
    "    - y : un acide aminÃ© (sous forme de string)\n",
    "    - i : un entier compris entre -p et q-1 (inclus)\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction Phi_i(x,y)\n",
    "    '''\n",
    "    if (x == y) :\n",
    "        return ( amino_acid_s_values.loc[x, i] + math.log(1 + math.exp(amino_acid_s_values.loc[x, i])) )\n",
    "    else :\n",
    "        return ( amino_acid_s_values.loc[x, i] + amino_acid_s_values.loc[y, i] )\n",
    "\n",
    "def LogKernel(x : str, y : str) :\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel probabiliste\n",
    "    ### Parameters:\n",
    "    - x : une sequence d'acides aminÃ©s de taille p+q (sous forme de string)\n",
    "    - y : une sequence d'acides aminÃ©s de taille p+q (sous forme de string)\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction LogKernel(x,y)\n",
    "    '''\n",
    "    sum = 0\n",
    "    for i in range(-p, q) :\n",
    "        sum += Phi(x[p+i], y[p+i], i)\n",
    "        #print(\"Sum :\"+ str(sum))\n",
    "    return sum\n",
    "\n",
    "def ProbalisticKernelB(x, y) :\n",
    "    x_str = fsl2.vector_to_word(x)\n",
    "    y_str = fsl2.vector_to_word(y)\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel probabiliste\n",
    "    ### Parameters:\n",
    "    - x : une sequence d'acides aminÃ©s converti au prealable en vecteur de taille (p+q)*26 composÃ© de 0 et 1\n",
    "    - y : une sequence d'acides aminÃ©s converti au prealable en vecteur de taille (p+q)*26 composÃ© de 0 et 1\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction Kernel(x,y)\n",
    "    '''\n",
    "    return math.exp(LogKernel(x_str, y_str))\n",
    "\n",
    "def ProbalisticKernel(X, Y):\n",
    "    # Initialize an empty matrix to store the kernel values\n",
    "    gram_matrix = np.zeros((X.shape[0], Y.shape[0]))\n",
    "\n",
    "    # Calculate the kernel value for each pair of samples\n",
    "    for i, x in enumerate(X):\n",
    "        for j, y in enumerate(Y):\n",
    "            x_str = fsl2.vector_to_word(x)\n",
    "            y_str = fsl2.vector_to_word(y)\n",
    "            gram_matrix[i, j] = math.exp(LogKernel(x_str, y_str))\n",
    "\n",
    "    return gram_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploitable = fsl2.convert_df_to_vectors2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_random_subseq(row, n:int, nb_letters:int=26):\n",
    "    '''\n",
    "    Extract a random subsequence of length n from the primary structure and the annotation\n",
    "    ### Parameters:\n",
    "    - row: a row of the dataframe\n",
    "    - n: the length of the subsequence\n",
    "    - nb_letters: the number of letters in the alphabet\n",
    "    ### Returns:\n",
    "    - a pandas series containing the subsequence of the primary structure\n",
    "    -There should be as much valid sequences as invalid sequences\n",
    "    the subsequence of the annotation, the subsequence of the primary structure as a vector and \n",
    "    the position of the cleavage site in the subsequence\n",
    "    '''\n",
    "    bool_cleavage = False\n",
    "    random_double = np.random.random()\n",
    "    if random_double > 0.5:\n",
    "        bool_cleavage = True\n",
    "\n",
    "    if bool_cleavage:\n",
    "        start_index = row['Cleavage_Site'] - 13\n",
    "        end_index = start_index + n  #n = 13 + 2 = 15\n",
    "\n",
    "        neighborhood_check = True  # Define wheter the sequence if the right neighborhood of the cleavage site\n",
    "    else :\n",
    "        max_start_index = max(0, len(row['Primary Structure']) - n)  # Calculate the maximum possible start index\n",
    "        if max_start_index == 0:\n",
    "            start_index = 0  # if chain is too short, start at the beginning\n",
    "        else:\n",
    "            start_index = np.random.randint(0, max_start_index)  # Randomly select a start index\n",
    "        end_index = start_index + n  # Calculer l'indice de fin\n",
    "\n",
    "        neighborhood_check = True if (row['Cleavage_Site'] - start_index == 13) else False  # Define wheter the sequence if the right neighborhood of the cleavage site\n",
    "    \n",
    "    return pd.Series([row['Primary Structure'][start_index:end_index], row['P_Structure_vector'][start_index*nb_letters:end_index*nb_letters], neighborhood_check], index=['Primary Structure', 'P_Structure_vector', 'Neighborhood_bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split_random_pos_proba(df, n ,test_size=0.2, random_state=42):\n",
    "    '''\n",
    "    Split the data into training and testing sets\n",
    "    ### Parameters:\n",
    "    - df: the dataframe containing the data\n",
    "    - n: the length of the subsequence\n",
    "    - test_size: the proportion of the data to include in the test split\n",
    "    - random_state: the seed for the random number generator\n",
    "    ### Returns:\n",
    "    - X_train: the training set\n",
    "    - X_test: the testing set\n",
    "    - pos_train: the position of the cleavage site in the training set\n",
    "    - pos_test: the position of the cleavage site in the testing set\n",
    "    '''\n",
    "    df_random = df.apply(extract_random_subseq, axis=1, n=n)\n",
    "    X = np.array(df_random['P_Structure_vector'].tolist())\n",
    "    y = np.array(df_random['Neighborhood_bool'].tolist())   \n",
    "\n",
    "    X_train, X_test, bool_train, bool_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \"\"\"\n",
    "    test_size=0.2: This argument specifies the proportion of the dataset to include in the test split. \n",
    "    In this case, 20% of the data will be used for testing, and the remaining 80% will be used for training\n",
    "\n",
    "    random_state=42: This argument sets the seed for the random number generator that shuffles the data before splitting. \n",
    "    Setting a specific seed (like 42 in this case) ensures that the output is reproducible, i.e., \n",
    "    you'll get the same train/test split each time you run the code.\n",
    "    \"\"\"\n",
    "\n",
    "    return X_train, X_test, bool_train, bool_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "p, q = 13, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developpement et entrainement du modÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1126, 390)\n",
      "\n",
      "\n",
      "569\n",
      "1126\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, bool_train, bool_test = test_train_split_random_pos_proba(df_exploitable, n)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "count_true = 0\n",
    "count_all = 0\n",
    "for t in bool_train:\n",
    "    count_all += 1\n",
    "    if t:\n",
    "        count_true += 1\n",
    "print(\"\\n\")\n",
    "print(count_true)\n",
    "print(count_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7836879432624113\n"
     ]
    }
   ],
   "source": [
    "probabilisticClassifier = svm.SVC(kernel=ProbalisticKernel)\n",
    "\n",
    "probabilisticClassifier.fit(X_train, bool_train)\n",
    "\n",
    "bool_pred = probabilisticClassifier.predict(X_test)\n",
    "\n",
    "print(accuracy_score(bool_test, bool_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'correct_neighborhood' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect_neighborhood\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m fsl2\u001b[38;5;241m.\u001b[39mword_to_vector(x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'correct_neighborhood' is not defined"
     ]
    }
   ],
   "source": [
    "x = correct_neighborhood.get(0)\n",
    "print(x)\n",
    "x = fsl2.word_to_vector(x)\n",
    "print(x)\n",
    "test = probabilisticClassifier.predict([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[209], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m count_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(correct_neighborhood)):\n\u001b[0;32m----> 3\u001b[0m     test \u001b[38;5;241m=\u001b[39m \u001b[43mprobabilisticClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsl2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_to_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrect_neighborhood\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(test):\n\u001b[1;32m      5\u001b[0m         count_fn \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/sklearn/svm/_base.py:814\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    812\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/sklearn/svm/_base.py:431\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[1;32m    430\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/sklearn/svm/_base.py:434\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dense_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 434\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    436\u001b[0m         X \u001b[38;5;241m=\u001b[39m check_array(X, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/sklearn/svm/_base.py:508\u001b[0m, in \u001b[0;36mBaseLibSVM._compute_kernel\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the data transformed by a callable kernel\"\"\"\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# in the case of precomputed kernel given as a function, we\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;66;03m# have to compute explicitly the kernel matrix\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__Xfit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(kernel):\n\u001b[1;32m    510\u001b[0m         kernel \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "Cell \u001b[0;32mIn[206], line 56\u001b[0m, in \u001b[0;36mProbalisticKernel\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Y):\n\u001b[0;32m---> 56\u001b[0m         x_str \u001b[38;5;241m=\u001b[39m \u001b[43mfsl2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_to_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m         y_str \u001b[38;5;241m=\u001b[39m fsl2\u001b[38;5;241m.\u001b[39mvector_to_word(y)\n\u001b[1;32m     58\u001b[0m         gram_matrix[i, j] \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mexp(LogKernel(x_str, y_str))\n",
      "File \u001b[0;32m~/Documents/GitHub/442-2-Protein-cleavage/fonctionsSupervisedLearning2.py:48\u001b[0m, in \u001b[0;36mvector_to_word\u001b[0;34m(vec)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvector_to_word\u001b[39m(vec):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Define a function to decode a vector into a word\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvec\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m26\u001b[39m):\n\u001b[1;32m     49\u001b[0m         word \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39minverse_transform([np\u001b[38;5;241m.\u001b[39margmax(vec[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m26\u001b[39m])])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "count_fn = 0\n",
    "for i in range(0, len(correct_neighborhood)):\n",
    "    test = probabilisticClassifier.predict(fsl2.word_to_vector(correct_neighborhood.get(i)))\n",
    "    if not(test):\n",
    "        count_fn += 1\n",
    "\n",
    "print(\"Nombre de faux nÃ©gatifs :\" + str(count_fn))\n",
    "\n",
    "count_fp = 0\n",
    "for i in range(0, len(incorrect_neighborhood)):\n",
    "    try : \n",
    "        test = fsl2.is_neighborhood2(incorrect_neighborhood.get(i), probabilisticClassifier, 15)\n",
    "        if test:\n",
    "            count_fp += 1\n",
    "    except:\n",
    "        print(\"Erreur\" + str(i))\n",
    "        #print(incorrect_neighborhood.get(i))\n",
    "\n",
    "\n",
    "print(\"Nombre de faux positifs :\" + str(count_fp))\n",
    "print(\"Nombre total :\" + str(len(correct_neighborhood)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
