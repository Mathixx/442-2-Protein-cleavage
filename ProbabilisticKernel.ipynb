{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessarry dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/4cr2jl295bs4z4czxy_p6w5m0000gn/T/ipykernel_99568/3029273363.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from auxFonctions import AminoAcid\n",
    "import fonctionsSupervisedLearning2 as fsl2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "\n",
    "from Bio.Align import substitution_matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redoing fast the Statistical Study in order to get the s values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from a file into a list of entries\n",
    "with open('data/SIG_13.red', 'r') as file:\n",
    "    entries = file.read().split('\\n   ')\n",
    "\n",
    "\n",
    "# Define a function to process each entry in the data file\n",
    "def process_entry(entry):\n",
    "    lines = entry.split('\\n')\n",
    "    protein_id, primary_structure, annotation = lines\n",
    "    return {\n",
    "        'Protein ID': protein_id.split()[1],\n",
    "        'Primary Structure': primary_structure,\n",
    "        'Annotation': annotation\n",
    "    }\n",
    "\n",
    "\n",
    "# Process each entry\n",
    "processed_entries = [process_entry(entry) for entry in entries]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(processed_entries)\n",
    "df['Cleavage_Site'] = df['Annotation'].apply(lambda x: x.find('C'))\n",
    "\n",
    "# Now you can analyze the DataFrame as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average position of the cleavage site:\n",
      "24.04971590909091\n",
      "\n",
      "\n",
      "The extremum position of the cleavage site:\n",
      "13\n",
      "90\n",
      "The distance from cleavage site to the C-terminal part of the amino-sequence:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the position of the cleavage site\n",
    "cleavage_site_position = df['Cleavage_Site']\n",
    "#print(\"Position of the cleavage site:\")\n",
    "#print(cleavage_site_position)\n",
    "print(\"Average position of the cleavage site:\")\n",
    "print(cleavage_site_position.mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"The extremum position of the cleavage site:\")\n",
    "print(cleavage_site_position.min())\n",
    "print(cleavage_site_position.max())\n",
    "\n",
    "print(\"The distance from cleavage site to the C-terminal part of the amino-sequence:\")\n",
    "#there is always 30 amino-acids after the cleavage site\n",
    "print(\"\\n\")\\\n",
    "\n",
    "# with have then p = [13, 1] and q = [1, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the primary structure into a list of amino acids\n",
    "amino_acid_seq = df['Primary Structure'].apply(lambda x: list(x))\n",
    "\n",
    "# Create a DataFrame to store, for each primary structure, the neihborhood of the cleavage site\n",
    "# The neighborhood is defined as the word of length p+q starting p letters before the cleavage site\n",
    "correct_neighborhood = pd.Series(index=amino_acid_seq.index, dtype=str)\n",
    "for i, seq in amino_acid_seq.items():\n",
    "    correct_neighborhood[i] = ''.join(seq[cleavage_site_position[i]-13:cleavage_site_position[i]+2])\n",
    "\n",
    "# for each amino acid in the sequence, replace it with the corresponding AminoAcid object\n",
    "amino_acid_seqB = amino_acid_seq\n",
    "amino_acid_seq = amino_acid_seq.apply(lambda x: [AminoAcid(aa) for aa in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametres de l'étude\n",
    "p = 13\n",
    "q = 2\n",
    "\n",
    "# Create a DataFrame to store the counts of each amino acid at every position relative to the cleavage site\n",
    "#the cleavage site is between to aminoacids, so cleavage_site_position is the position of the first amino acid after the cleavge site\n",
    "#So i need to create a dataframe with columns from -p to q without 0\n",
    "amino_acid_counts = pd.DataFrame(0, index=AminoAcid.properties.keys(), columns=range(-p, q))\n",
    "amino_acid_freqs = pd.DataFrame(0.0, index=AminoAcid.properties.keys(), columns=range(-p, q)) #f(a,i)\n",
    "amino_acid_pseudo_counts = pd.DataFrame(0, index=AminoAcid.properties.keys(), columns=range(-p, q)) #g(a)\n",
    "amino_acid_s_values = pd.DataFrame(0.0, index=AminoAcid.properties.keys(), columns=range(-p, q)) #s(a,i)\n",
    "\n",
    "\n",
    "# Count the occurrences of each amino acid at every position relative to the cleavage site\n",
    "\n",
    "for i, seq in amino_acid_seq.items():\n",
    "    for j, aa in enumerate(seq):\n",
    "        position = j - cleavage_site_position[i] #position of the amino acid relative to the cleavage site\n",
    "        if position in amino_acid_counts.columns:\n",
    "            amino_acid_counts.loc[aa.code, position] += 1\n",
    "\n",
    "# Add pseudo-counts to avoid zero counts here pseudocount parameter is 1/len(df)\n",
    "amino_acid_pseudo_counts = amino_acid_counts + 1\n",
    "\n",
    "# Print the results\n",
    "#print(\"Occurrences of each amino acid at every position relative to the cleavage site:\")\n",
    "#print(amino_acid_pseudo_counts)\n",
    "\n",
    "# Compute the observed frequency of each amino acid at the relative position (using pseudo-counts)\n",
    "for i in amino_acid_counts.index:\n",
    "    for j in amino_acid_counts.columns:\n",
    "        amino_acid_freqs.loc[i, j] = amino_acid_pseudo_counts.loc[i, j] / len(df)\n",
    "\n",
    "# Compute the general background frequency of each amino acid\n",
    "general_background_frequency = amino_acid_freqs.mean(axis=1)\n",
    "\n",
    "# Compute the s value of each amino acid at every position\n",
    "for i in amino_acid_counts.index:\n",
    "    for j in amino_acid_counts.columns:\n",
    "        amino_acid_s_values.loc[i, j] = math.log(amino_acid_freqs.loc[i, j]) - math.log(general_background_frequency[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store, for each primary structure, the neihborhood of the cleavage site\n",
    "# The neighborhood is defined as the word of length p+q starting p letters before the cleavage site\n",
    "correct_neighborhood = pd.Series()\n",
    "for i, seq in amino_acid_seqB.items():\n",
    "    correct_neighborhood[i] = ''.join(seq[cleavage_site_position[i]-p:cleavage_site_position[i]+q])\n",
    "\n",
    "# Create a DataFrame to store, for each primary structure, a sequence that is not the neighborhood of the cleavage site\n",
    "incorrect_neighborhood = pd.Series()\n",
    "decalage  = [1,2,3,4,5, -1,-2,-3,-4, -5]\n",
    "for i, seq in amino_acid_seqB.items():\n",
    "    dec = np.random.choice(decalage)\n",
    "    dec = 0 if cleavage_site_position[i]-13 - dec < 0 else dec\n",
    "    incorrect_neighborhood[i] = ''.join(seq[cleavage_site_position[i]-p-dec:cleavage_site_position[i]+q-dec])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.302718213229582"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function computing the q-1 score for a given word\n",
    "def q_minus_1_score(word):\n",
    "    return sum([amino_acid_s_values.loc[aa, i-p] for i, aa in enumerate(word)])\n",
    "\n",
    "\n",
    "#A REDEFINIR EN FONCTION DES RESULTATS OBTENUS\n",
    "threshold = 1.5\n",
    "print(threshold)\n",
    "\n",
    "#A simple thresholding (to be tuned) is then enough to define a simple binary classifier.\n",
    "def is_cleavage_neighborhood(score):\n",
    "    return score > threshold\n",
    "\n",
    "q_minus_1_score('AAAAAAAAAAAAAAA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score of the correct neighborhoods:\n",
      "3.2162682210182796\n",
      "\n",
      "\n",
      "Mean score of the incorrect neighborhoods:\n",
      "-1.382802638517708\n",
      "\n",
      "\n",
      "Standard deviation of the score of the correct neighborhoods:\n",
      "2.5872637135991514\n",
      "Standard deviation of the score of the incorrect neighborhoods:\n",
      "2.641542360016145\n",
      "Min and max values of the correct neighboorhoods score :\n",
      "-7.931205228611351\n",
      "9.452566054567916\n",
      "Min and max values of the incorrect neighboorhoods score :\n",
      "-10.246704169195642\n",
      "6.822429937204971\n",
      "False negative out of 1408 entries:\n",
      "288\n",
      "False positive out of 1408 entries:\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "# To obtain the score of the correct neighborhoods, we apply the q-1 score function to each neighborhood\n",
    "#correct_neighborhood = correct_neighborhood.apply(lambda x: [AminoAcid(aa) for aa in x])\n",
    "correct_neigboorhood_score = correct_neighborhood.apply(q_minus_1_score)\n",
    "incorrect_neighborhood_score = incorrect_neighborhood.apply(q_minus_1_score)\n",
    "\n",
    "#print(\"Score of the correct neighborhoods:\")\n",
    "#print(correct_neigboorhood_score)\n",
    "#print(\"\\n\")\n",
    "\n",
    "print(\"Mean score of the correct neighborhoods:\")\n",
    "print(correct_neigboorhood_score.mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean score of the incorrect neighborhoods:\")\n",
    "print(incorrect_neighborhood_score.mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Standard deviation of the score of the correct neighborhoods:\")\n",
    "print(correct_neigboorhood_score.std())\n",
    "\n",
    "print(\"Standard deviation of the score of the incorrect neighborhoods:\")\n",
    "print(incorrect_neighborhood_score.std())\n",
    "\n",
    "print(\"Min and max values of the correct neighboorhoods score :\")\n",
    "print(correct_neigboorhood_score.min())\n",
    "print(correct_neigboorhood_score.max())\n",
    "\n",
    "print(\"Min and max values of the incorrect neighboorhoods score :\")\n",
    "print(incorrect_neighborhood_score.min())\n",
    "print(incorrect_neighborhood_score.max())\n",
    "\n",
    "#We now test, with the updated threshold, the performance of the classifier on the training set\n",
    "# Treshold = mean - std\n",
    "false_negatives = correct_neigboorhood_score[correct_neigboorhood_score < threshold].count()\n",
    "print(\"False negative out of \"+str(len(correct_neighborhood))+ \" entries:\")\n",
    "print(false_negatives)\n",
    "\n",
    "false_positives = incorrect_neighborhood_score[incorrect_neighborhood_score > threshold].count()\n",
    "print(\"False positive out of \"+str(len(incorrect_neighborhood))+ \" entries:\")\n",
    "print(false_positives)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILISATION DES RESULTATS POUR CREER LA KERNEL PROBABILISTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_un_caractere(obj):\n",
    "    return isinstance(obj, str) and len(obj) == 1\n",
    "\n",
    "def Phi(x : chr, y : chr, i : int) :\n",
    "    if not(est_un_caractere(x) and est_un_caractere(y)) :\n",
    "        raise ValueError(\"x and y must be single characters\")\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel probabiliste\n",
    "    ### Parameters:\n",
    "    - x : un acide aminé (sous forme de string)\n",
    "    - y : un acide aminé (sous forme de string)\n",
    "    - i : un entier compris entre -p et q-1 (inclus)\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction Phi_i(x,y)\n",
    "    '''\n",
    "    if (x == y) :\n",
    "        return ( amino_acid_s_values.loc[x, i] + math.log(1 + math.exp(amino_acid_s_values.loc[x, i])) )\n",
    "    else :\n",
    "        return ( amino_acid_s_values.loc[x, i] + amino_acid_s_values.loc[y, i] )\n",
    "\n",
    "def LogKernel(x : str, y : str) :\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel probabiliste\n",
    "    ### Parameters:\n",
    "    - x : une sequence d'acides aminés de taille p+q (sous forme de string)\n",
    "    - y : une sequence d'acides aminés de taille p+q (sous forme de string)\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction LogKernel(x,y)\n",
    "    '''\n",
    "    sum = 0\n",
    "    for i in range(-p, q) :\n",
    "        sum += Phi(x[p+i], y[p+i], i)\n",
    "        #print(\"Sum :\"+ str(sum))\n",
    "    return sum\n",
    "\n",
    "\"\"\"\n",
    "def ProbalisticKernel(X, Y):\n",
    "    # Initialize an empty matrix to store the kernel values\n",
    "    gram_matrix = np.zeros((X.shape[0], Y.shape[0]))\n",
    "\n",
    "    # Calculate the kernel value for each pair of samples\n",
    "    for i, x in enumerate(X):\n",
    "        for j, y in enumerate(Y):\n",
    "            x_str = fsl2.vector_to_word(x)\n",
    "            y_str = fsl2.vector_to_word(y)\n",
    "            gram_matrix[i, j] = math.exp(LogKernel(x_str, y_str))\n",
    "\n",
    "    return gram_matrix\n",
    "\"\"\"\n",
    "\n",
    "def ProbKernel(x, y):\n",
    "    X_str = fsl2.vector_to_word(x)\n",
    "    Y_str = fsl2.vector_to_word(y)\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel probabiliste\n",
    "    ### Parameters:\n",
    "    - x : une sequence d'acides aminés converti au prealable en vecteur de taille (p+q)*26 composé de 0 et 1\n",
    "    - y : une sequence d'acides aminés converti au prealable en vecteur de taille (p+q)*26 composé de 0 et 1\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction Kernel(x,y)\n",
    "    '''\n",
    "    return math.exp(LogKernel(X_str, Y_str))\n",
    "\n",
    "def ProbabilisticKernel(X, Y):\n",
    "    # Initialize an empty matrix to store the kernel values\n",
    "    gram_matrix = np.zeros((X.shape[0], Y.shape[0]))\n",
    "\n",
    "    # Calculate the kernel value for each pair of samples\n",
    "    for i, x in enumerate(X):\n",
    "        for j, y in enumerate(Y):\n",
    "            gram_matrix[i, j] = ProbKernel(x, y)\n",
    "\n",
    "    return gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9846.188567738474\n"
     ]
    }
   ],
   "source": [
    "x = fsl2.word_to_vector(correct_neighborhood[0])\n",
    "y = fsl2.word_to_vector(correct_neighborhood[1])\n",
    "\n",
    "print(ProbKernel(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KERNEL ISSUE DES MATRICES DE SUBSTITUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for A and R: -1.0\n",
      "Score for A and A: 2.0\n",
      "Score for A and A: 4.0\n"
     ]
    }
   ],
   "source": [
    "pam250 = substitution_matrices.load(\"PAM250\")\n",
    "blosum62 = substitution_matrices.load(\"BLOSUM62\")\n",
    "\n",
    "# Access scores directly\n",
    "score_AR = pam250[('A', 'K')]\n",
    "print(\"Score for A and R:\", score_AR)\n",
    "\n",
    "score_AA = pam250['A', 'A']\n",
    "print(\"Score for A and A:\", score_AA)\n",
    "\n",
    "score_AA = blosum62['A', 'A']\n",
    "print(\"Score for A and A:\", score_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction indiquant la similarité entre deux sequences d'acides aminés\n",
    "def SimilarityPAM(x : str, y : str) :\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel probabiliste\n",
    "    ### Parameters:\n",
    "    - x : une sequence d'acides aminés de taille p+q (sous forme de string)\n",
    "    - y : une sequence d'acides aminés de taille p+q (sous forme de string)\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction Similarity(x,y)\n",
    "    '''\n",
    "    sum = 0\n",
    "    for i in range(-p, q) :\n",
    "        sum += pam250[(x[p+i], y[p+i])]\n",
    "    return sum\n",
    "\n",
    "def SimilarityBLOSUM(x : str, y : str) :\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel probabiliste\n",
    "    ### Parameters:\n",
    "    - x : une sequence d'acides aminés de taille p+q (sous forme de string)\n",
    "    - y : une sequence d'acides aminés de taille p+q (sous forme de string)\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction Similarity(x,y)\n",
    "    '''\n",
    "    sum = 0\n",
    "    for i in range(-p, q) :\n",
    "        sum += blosum62[x[p+i], y[p+i]]\n",
    "    return sum\n",
    "\n",
    "def RBF_similarity(x : str, y : str, sigma = 1, SUBSTITUTION_MATRIX = \"PAM\") :\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel de similarité\n",
    "    ### Parameters:\n",
    "    - x : une sequence d'acides aminés de taille p+q (sous forme de string)\n",
    "    - y : une sequence d'acides aminés de taille p+q (sous forme de string)\n",
    "    - sigma : un reel positif\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction Similarity(x,y)\n",
    "    '''\n",
    "    if (SUBSTITUTION_MATRIX == \"PAM\") :\n",
    "        Similarity = SimilarityPAM\n",
    "    elif (SUBSTITUTION_MATRIX == \"BLOSUM\") :\n",
    "        Similarity = SimilarityBLOSUM\n",
    "    return math.exp(-Similarity(x, y) / (2 * sigma**2))\n",
    "\n",
    "def RBF_kernelPAM(X, Y) :\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel RBF (Radial Basis Function) par similarité\n",
    "    ### Parameters:\n",
    "    - x : une sequence d'acides aminés converti au prealable en vecteur de taille (p+q)*26 composé de 0 et 1\n",
    "    - y : une sequence d'acides aminés converti au prealable en vecteur de taille (p+q)*26 composé de 0 et 1\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction Kernel(x,y)\n",
    "    '''\n",
    "    # Initialize an empty matrix to store the kernel values\n",
    "    Xb = X\n",
    "    Yb = Y\n",
    "    if Xb.ndim == 1:\n",
    "        Xb = np.array([Xb])\n",
    "    if Yb.ndim == 1:\n",
    "        Yb = np.array([Yb])\n",
    "    gram_matrix = np.zeros((Xb.shape[0], Yb.shape[0]))\n",
    "\n",
    "    # Calculate the kernel value for each pair of samples\n",
    "    for i, x in enumerate(Xb):\n",
    "        X_str = fsl2.vector_to_word(x)\n",
    "        for j, y in enumerate(Yb):\n",
    "            Y_str = fsl2.vector_to_word(y)\n",
    "            gram_matrix[i, j] = RBF_similarity(X_str, Y_str, sigma = 0.5, SUBSTITUTION_MATRIX = \"PAM\") \n",
    "\n",
    "    return gram_matrix\n",
    "\n",
    "def RBF_kernelBLOSUM(X, Y) :\n",
    "    '''\n",
    "    Fonction servant de base a la Kernel RBF (Radial Basis Function) par similarité\n",
    "    ### Parameters:\n",
    "    - x : une sequence d'acides aminés converti au prealable en vecteur de taille (p+q)*26 composé de 0 et 1\n",
    "    - y : une sequence d'acides aminés converti au prealable en vecteur de taille (p+q)*26 composé de 0 et 1\n",
    "    ### Returns:\n",
    "    - La valeur de la fonction Kernel(x,y)\n",
    "    '''\n",
    "    # Initialize an empty matrix to store the kernel values\n",
    "    Xb = X\n",
    "    Yb = Y\n",
    "    if Xb.ndim == 1:\n",
    "        Xb = np.array([Xb])\n",
    "    if Yb.ndim == 1:\n",
    "        Yb = np.array([Yb])\n",
    "    gram_matrix = np.zeros((Xb.shape[0], Yb.shape[0]))\n",
    "\n",
    "    # Calculate the kernel value for each pair of samples\n",
    "    for i, x in enumerate(Xb):\n",
    "        X_str = fsl2.vector_to_word(x)\n",
    "        for j, y in enumerate(Yb):\n",
    "            Y_str = fsl2.vector_to_word(y)\n",
    "            gram_matrix[i, j] = RBF_similarity(X_str, Y_str, sigma = 5, SUBSTITUTION_MATRIX = \"BLOSUM\") \n",
    "\n",
    "    return gram_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploitable = fsl2.convert_df_to_vectors2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_random_subseq(row, n:int, nb_letters:int=26):\n",
    "    '''\n",
    "    Extract a random subsequence of length n from the primary structure and the annotation\n",
    "    ### Parameters:\n",
    "    - row: a row of the dataframe\n",
    "    - n: the length of the subsequence\n",
    "    - nb_letters: the number of letters in the alphabet\n",
    "    ### Returns:\n",
    "    - a pandas series containing the subsequence of the primary structure\n",
    "    -There should be as much valid sequences as invalid sequences\n",
    "    the subsequence of the annotation, the subsequence of the primary structure as a vector and \n",
    "    the position of the cleavage site in the subsequence\n",
    "    '''\n",
    "    bool_cleavage = False\n",
    "    random_double = np.random.random()\n",
    "    if random_double > 0.5:\n",
    "        bool_cleavage = True\n",
    "\n",
    "    if bool_cleavage:\n",
    "        start_index = row['Cleavage_Site'] - 13\n",
    "        end_index = start_index + n  #n = 13 + 2 = 15\n",
    "\n",
    "        neighborhood_check = 1  # Define wheter the sequence if the right neighborhood of the cleavage site\n",
    "    else :\n",
    "        max_start_index = max(0, len(row['Primary Structure']) - n)  # Calculate the maximum possible start index\n",
    "        if max_start_index == 0:\n",
    "            start_index = 0  # if chain is too short, start at the beginning\n",
    "        else:\n",
    "            start_index = np.random.randint(0, max_start_index)  # Randomly select a start index\n",
    "        end_index = start_index + n  # Calculer l'indice de fin\n",
    "\n",
    "        neighborhood_check = 1 if (row['Cleavage_Site'] - start_index == 13) else 0  # Define wheter the sequence if the right neighborhood of the cleavage site\n",
    "    \n",
    "    return pd.Series([row['Primary Structure'][start_index:end_index], row['P_Structure_vector'][start_index*nb_letters:end_index*nb_letters], neighborhood_check], index=['Primary Structure', 'P_Structure_vector', 'Neighborhood_bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split_random_pos_proba(df, n ,test_size=0.2, random_state=42):\n",
    "    '''\n",
    "    Split the data into training and testing sets\n",
    "    ### Parameters:\n",
    "    - df: the dataframe containing the data\n",
    "    - n: the length of the subsequence\n",
    "    - test_size: the proportion of the data to include in the test split\n",
    "    - random_state: the seed for the random number generator\n",
    "    ### Returns:\n",
    "    - X_train: the training set\n",
    "    - X_test: the testing set\n",
    "    - pos_train: the position of the cleavage site in the training set\n",
    "    - pos_test: the position of the cleavage site in the testing set\n",
    "    '''\n",
    "    df_random = df.apply(extract_random_subseq, axis=1, n=n)\n",
    "    X = np.array(df_random['P_Structure_vector'].tolist())\n",
    "    y = np.array(df_random['Neighborhood_bool'].tolist())   \n",
    "\n",
    "    X_train, X_test, bool_train, bool_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \"\"\"\n",
    "    test_size=0.2: This argument specifies the proportion of the dataset to include in the test split. \n",
    "    In this case, 20% of the data will be used for testing, and the remaining 80% will be used for training\n",
    "\n",
    "    random_state=42: This argument sets the seed for the random number generator that shuffles the data before splitting. \n",
    "    Setting a specific seed (like 42 in this case) ensures that the output is reproducible, i.e., \n",
    "    you'll get the same train/test split each time you run the code.\n",
    "    \"\"\"\n",
    "\n",
    "    return X_train, X_test, bool_train, bool_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "p, q = 13, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developpement et entrainement du modèle probabiliste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1126, 390)\n",
      "\n",
      "\n",
      "569\n",
      "1126\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, bool_train, bool_test = test_train_split_random_pos_proba(df_exploitable, n)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "count_true = 0\n",
    "count_all = 0\n",
    "for t in bool_train:\n",
    "    count_all += 1\n",
    "    if t:\n",
    "        count_true += 1\n",
    "print(\"\\n\")\n",
    "print(count_true)\n",
    "print(count_all)\n",
    "\n",
    "gram_matrix = ProbabilisticKernel(X_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7624113475177305\n"
     ]
    }
   ],
   "source": [
    "probabilisticClassifier = svm.SVC(kernel='precomputed')\n",
    "\n",
    "probabilisticClassifier.fit(gram_matrix, bool_train)\n",
    "\n",
    "gram_matrix_test = ProbabilisticKernel(X_test, X_train)\n",
    "\n",
    "bool_pred = probabilisticClassifier.predict(gram_matrix_test)\n",
    "\n",
    "print(accuracy_score(bool_test, bool_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLAFTLLFATCIARH\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]]\n",
      "[False]\n"
     ]
    }
   ],
   "source": [
    "x = correct_neighborhood.get(0)\n",
    "print(x)\n",
    "x = fsl2.word_to_vector(x)\n",
    "x = np.array([x])\n",
    "k_x = ProbabilisticKernel(x, X_train)\n",
    "print(x)\n",
    "test = probabilisticClassifier.predict(k_x)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de faux négatifs :412\n",
      "Nombre de faux positifs :57\n",
      "Nombre total :1408\n"
     ]
    }
   ],
   "source": [
    "count_fn = 0\n",
    "for i in range(0, len(correct_neighborhood)):\n",
    "    x = np.array([fsl2.word_to_vector(correct_neighborhood.get(i))])\n",
    "    K_x = ProbabilisticKernel(x, X_train)\n",
    "    test = probabilisticClassifier.predict(K_x)\n",
    "    if not(test):\n",
    "        count_fn += 1\n",
    "\n",
    "print(\"Nombre de faux négatifs :\" + str(count_fn))\n",
    "\n",
    "count_fp = 0\n",
    "for i in range(0, len(incorrect_neighborhood)):\n",
    "    try : \n",
    "        x = np.array([fsl2.word_to_vector(incorrect_neighborhood.get(i))])\n",
    "        K_x = ProbabilisticKernel(x, X_train)\n",
    "        test = probabilisticClassifier.predict(K_x)\n",
    "        if test:\n",
    "            count_fp += 1\n",
    "    except:\n",
    "        print(\"Erreur\" + str(i))\n",
    "        #print(incorrect_neighborhood.get(i))\n",
    "\n",
    "\n",
    "print(\"Nombre de faux positifs :\" + str(count_fp))\n",
    "print(\"Nombre total :\" + str(len(correct_neighborhood)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developpement et entrainement du modèle similarité\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570\n",
      "1126\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, bool_train, bool_test = test_train_split_random_pos_proba(df_exploitable, n)\n",
    "\n",
    "count_true = 0\n",
    "count_all = 0\n",
    "for t in bool_train:\n",
    "    count_all += 1\n",
    "    if t:\n",
    "        count_true += 1\n",
    "print(count_true)\n",
    "print(count_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "[1 4]\n",
      "Predicted labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Define a custom kernel function (e.g., a simple polynomial kernel)\n",
    "def polynomial_kernel(X, Y):\n",
    "    return (1 + np.dot(X, Y.T))**2  # (x*y' + 1)^2\n",
    "\n",
    "# Example data\n",
    "X_train = np.array([[0, 0], [1, 1], [1, 0], [0, 1]])\n",
    "y_train = [0, 1, 1, 0]\n",
    "\n",
    "print(X_train.ndim)\n",
    "print(X_train[0].ndim)\n",
    "\n",
    "test = polynomial_kernel([X_train[0], X_train[2]], X_train[1])\n",
    "\n",
    "print(test)\n",
    "\n",
    "# Create the SVM with the custom kernel function\n",
    "clf = svm.SVC(kernel=polynomial_kernel)\n",
    "\n",
    "# Train the model using the feature vectors directly\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels on new data\n",
    "X_test = np.array([[0, 0], [1, 1]])\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Predicted labels:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with sigma = 0.5 and BLOSUM:\n",
      "0.1347517730496454\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf_BLOSUM = svm.SVC(kernel=RBF_kernelBLOSUM)\n",
    "clf_BLOSUM.fit(X_train, bool_train)\n",
    "\n",
    "bool_pred_BLOSUM = clf_BLOSUM.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy score with sigma = 0.5 and BLOSUM:\")\n",
    "print(accuracy_score(bool_test, bool_pred_BLOSUM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLAFTLLFATCIARH\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]]\n",
      "[False]\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "x = correct_neighborhood.get(0)\n",
    "print(x)\n",
    "x = fsl2.word_to_vector(x)\n",
    "x = np.array([x])\n",
    "print(x)\n",
    "test = clf_BLOSUM.predict(x)\n",
    "print(test)\n",
    "if not(test) :\n",
    "    print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de faux négatifs :1193\n",
      "Nombre de faux positifs :798\n",
      "Nombre total :1408\n"
     ]
    }
   ],
   "source": [
    "count_fn = 0\n",
    "for i in range(0, len(correct_neighborhood)):\n",
    "    x = np.array([fsl2.word_to_vector(correct_neighborhood.get(i))])\n",
    "    test = clf_BLOSUM.predict(x)\n",
    "    if (test == 0):\n",
    "        count_fn += 1\n",
    "\n",
    "print(\"Nombre de faux négatifs :\" + str(count_fn))\n",
    "\n",
    "count_fp = 0\n",
    "for i in range(0, len(incorrect_neighborhood)):\n",
    "    try : \n",
    "        x = np.array([fsl2.word_to_vector(incorrect_neighborhood.get(i))])\n",
    "        test = clf_BLOSUM.predict(x)\n",
    "        if (test == 1):\n",
    "            count_fp += 1\n",
    "    except:\n",
    "        print(\"Erreur\" + str(i))\n",
    "        #print(incorrect_neighborhood.get(i))\n",
    "\n",
    "\n",
    "print(\"Nombre de faux positifs :\" + str(count_fp))\n",
    "print(\"Nombre total :\" + str(len(correct_neighborhood)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
