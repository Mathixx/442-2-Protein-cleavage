{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### MODULES NECESSAIRES ###\n",
    "###########################\n",
    "\n",
    "\n",
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import fonctionsSupervisedLearning1 as fsl\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "\n",
    "from auxFonctions import AminoAcid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from a file into a list of entries\n",
    "with open('data/SIG_13.red', 'r') as file:\n",
    "    entries = file.read().split('\\n   ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## RECUPERATION DES DONNÉES ##\n",
    "##############################\n",
    "\n",
    "\n",
    "# Process each entry\n",
    "processed_entries = [fsl.process_entry(entry) for entry in entries]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(processed_entries)\n",
    "\n",
    "# Get the position of the cleavage site\n",
    "df['position'] = df['Annotation'].apply(lambda x: x.find('C'))\n",
    "\n",
    "# Split the primary structure into a list of amino acids\n",
    "amino_acid_seq = df['Primary Structure'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put words in vector and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploitable = fsl.convert_df_to_vectors(df)\n",
    "df_exploitable.to_csv('data/df_exploitable.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_pq(df, kernel = 'rbf', C = 10, p = 2, q = 13, random_state = 42):\n",
    "    gamma = 0.1\n",
    "    \n",
    "    X_train, X_test, pos_train, pos_test = fsl.test_train_split_random_pos(df, p+q, random_state=random_state)\n",
    "    pos_train = np.array(pos_train==p)\n",
    "    print(X_train[pos_train==1])\n",
    "    pos_test = np.array(pos_test==p)\n",
    "    svm_model = svm.SVC(kernel=kernel, C=C,gamma=gamma, random_state=random_state)\n",
    "    svm_model.fit(X_train, pos_train)\n",
    "    pos_predict = svm_model.predict(X_test)\n",
    "    accuracy = accuracy_score(pos_test,pos_predict)\n",
    "    # accuracy = 0\n",
    "    # svm_model = 0\n",
    "    return svm_model,accuracy\n",
    "\n",
    "def find_cleavage_pq (X, svm_model, p:int = 2, q:int = 13, nb_letters = 26):\n",
    "    '''\n",
    "    find the position of the cleavage site in the primary structure using two SVM models\n",
    "    /!\\ the models must be trained before using this function with the same n and nb_letters as the ones used in this function\n",
    "    ### Parameters:\n",
    "    - X: the primary structure as a vector\n",
    "    - svm_model_in: the SVM model that predicts if the subsequence contains the cleavage site\n",
    "    - svm_model_pos: the SVM model that predicts the position of the cleavage site in the subsequence\n",
    "    - threshold: the threshold for the confidence of the prediction\n",
    "    ### Returns:\n",
    "    - the position of the cleavage site if the prediction is confident enough, otherwise Nan\n",
    "    '''\n",
    "    positions = []\n",
    "    for i in range(p*nb_letters, len(X)- q*nb_letters, nb_letters):\n",
    "        test_sub = X[i-p*nb_letters :i + q*nb_letters]\n",
    "        \n",
    "        if svm_model.predict([test_sub]):\n",
    "            position = i//nb_letters\n",
    "            # positions.append(position.item())\n",
    "            return position\n",
    "    return math.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary Structure</th>\n",
       "      <th>cleavage</th>\n",
       "      <th>P_Structure_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IARHQQRQQQQNQCQ</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSQIEQQSPWEFQGS</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAGSHSMRYFYTSVS</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAAPANQFIKTSCTL</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NASIYRTVVEFEEDD</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>FAQDFCSNAQHSGQK</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>AACTYTIDSEWSTGF</td>\n",
       "      <td>True</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>FAEEPEDGNDGIPRL</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>VAATSTVTGGYAQSD</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>CAFSVDSMIKFSGED</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1408 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Primary Structure  cleavage  \\\n",
       "0      IARHQQRQQQQNQCQ      True   \n",
       "1      LSQIEQQSPWEFQGS      True   \n",
       "2      WAGSHSMRYFYTSVS      True   \n",
       "3      SAAPANQFIKTSCTL      True   \n",
       "4      NASIYRTVVEFEEDD      True   \n",
       "...                ...       ...   \n",
       "1403   FAQDFCSNAQHSGQK      True   \n",
       "1404   AACTYTIDSEWSTGF      True   \n",
       "1405   FAEEPEDGNDGIPRL      True   \n",
       "1406   VAATSTVTGGYAQSD      True   \n",
       "1407   CAFSVDSMIKFSGED      True   \n",
       "\n",
       "                                     P_Structure_vector  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "1403  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "1404  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1405  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "1406  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1407  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[1408 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract neighboorhood p+q of cleavage site\n",
    "def extract_neighboorhood(df, p:int = 2, q:int = 13, nb_letters = 26):\n",
    "    '''\n",
    "    extract the neighborhood of the cleavage site in the primary structure\n",
    "    ### Parameters:\n",
    "    - df: the dataframe containing the primary structure\n",
    "    - p: the number of amino acids before the cleavage site\n",
    "    - q: the number of amino acids after the cleavage site\n",
    "    - nb_letters: the number of amino acids in the alphabet\n",
    "    ### Returns:\n",
    "    - the dataframe with the neighborhood of the cleavage site\n",
    "    '''\n",
    "    df_neigh = df.copy()\n",
    "    for i in range(df.shape[0]):\n",
    "        X = df.iloc[i]['Primary Structure']\n",
    "        position = df.iloc[i]['position']\n",
    "        if position >= p and position <= len(X)-q:\n",
    "            neigh = X[(position-p):(position+q)]\n",
    "\n",
    "            df_neigh.at[i,'Primary Structure'] = neigh\n",
    "            df_neigh.at[i,'complete'] = True\n",
    "\n",
    "        elif position >= p:\n",
    "        # complete with Xs if the neighborhood is not complete\n",
    "            neigh = X[position-p:] + ['X']*(p+q-len(X[position-p:]))\n",
    "            df_neigh.at[i,'Primary Structure'] = neigh\n",
    "            df_neigh.at[i,'complete'] = False\n",
    "            \n",
    "        else:\n",
    "            neigh = ['X']*(p-len(X[:position])) + X[:position+q]\n",
    "            df_neigh.at[i,'Primary Structure'] = neigh\n",
    "            df_neigh.at[i,'complete'] = False\n",
    "    # set cleavage to true to all the lines\n",
    "    df_neigh['cleavage'] = True\n",
    "    #delete Protein ID and  Annotation position columns\n",
    "    df_neigh = df_neigh.drop(columns=['Protein ID','position','Annotation'])\n",
    "\n",
    "   \n",
    "\n",
    "    df_neigh = df_neigh[df_neigh['complete'] == True].drop(columns=['complete'])\n",
    "    return df_neigh\n",
    "\n",
    "\n",
    "df_neigh = extract_neighboorhood(df, p=2, q=13, nb_letters=26)\n",
    "df_neigh = fsl.convert_df_to_vectors(df_neigh)\n",
    "# df_neigh = df_neigh[df_neigh['complete'] == True]\n",
    "df_neigh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary Structure</th>\n",
       "      <th>cleavage</th>\n",
       "      <th>P_Structure_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KATLLLAFTLLFATC</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLCLAVFINGCLSQI</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RYFYTSVSRPGRGEP</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SALLVILAAASAAPA</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDASNPVGPRQRCQK</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>AFAQDFCSNAQHSGQ</td>\n",
       "      <td>False</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>STGAALAILSQAASA</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>PYAFAEEPEDGNDGI</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>LAFTAGTSVAATSTV</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>LLLPFFSCAFSVDSM</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1408 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Primary Structure  cleavage  \\\n",
       "0      KATLLLAFTLLFATC     False   \n",
       "1      FLCLAVFINGCLSQI     False   \n",
       "2      RYFYTSVSRPGRGEP     False   \n",
       "3      SALLVILAAASAAPA     False   \n",
       "4      DDASNPVGPRQRCQK     False   \n",
       "...                ...       ...   \n",
       "1403   AFAQDFCSNAQHSGQ     False   \n",
       "1404   STGAALAILSQAASA     False   \n",
       "1405   PYAFAEEPEDGNDGI     False   \n",
       "1406   LAFTAGTSVAATSTV     False   \n",
       "1407   LLLPFFSCAFSVDSM     False   \n",
       "\n",
       "                                     P_Structure_vector  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "1403  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1404  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1405  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1406  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1407  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[1408 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_random_from_row(row, p:int, q, nb_letters:int=26):\n",
    "    '''\n",
    "    Extract a random subsequence of length n from the primary structure and the annotation\n",
    "    ### Parameters:\n",
    "    - row: a row of the dataframe\n",
    "    - p+q: the length of the subsequence\n",
    "    - nb_letters: the number of letters in the alphabet\n",
    "    ### Returns:\n",
    "    - a pandas series containing the subsequence of the primary structure'''\n",
    "    n = p+q\n",
    "    max_start_index = max(0, len(row['Primary Structure']) - n)  # Calculate the maximum possible start index\n",
    "    if max_start_index == 0:\n",
    "        start_index = 0  # if chain is too short, start at the beginning\n",
    "    else:\n",
    "        start_index = np.random.randint(0, max_start_index)  # Randomly select a start index\n",
    "    end_index = start_index + n  # Calculer l'indice de fin\n",
    "\n",
    " # Calculate the position of the cleavage site in the subsequence\n",
    "    cleavage = False  # Initialize the cleavage variable\n",
    "    if row['position'] == p :  # If the cleavage site is in the right place in the subsequence\n",
    "        cleavage = True\n",
    "         # If the cleavage site is not in the subsequence, set it to Nan\n",
    "        \n",
    "\n",
    "    return pd.Series([row['Primary Structure'][start_index:end_index], cleavage], index=['Primary Structure','cleavage'])\n",
    "\n",
    "def extract_random_sequence(df, p, q):\n",
    "    '''\n",
    "    extract random sequences of length p+q from the primary structure\n",
    "    ### Parameters:\n",
    "    - df: the dataframe containing the primary structure\n",
    "    - p: the number of amino acids before the cleavage site\n",
    "    - q: the number of amino acids after the cleavage site\n",
    "    ### Returns:\n",
    "    - the dataframe with random sequences of length p+q\n",
    "    '''\n",
    "    df_random = df.apply(lambda x: extract_random_from_row(x, p,q), axis=1)\n",
    "    return df_random\n",
    "\n",
    "df_random = extract_random_sequence(df, p=2, q=13)\n",
    "df_random = fsl.convert_df_to_vectors(df_random)\n",
    "df_random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split2 (df_neigh, df_random, test_size = 0.2, random_state = 42):\n",
    "    '''\n",
    "    split the dataframe into a training and a testing set and convert it to vectors\n",
    "    ### Parameters:\n",
    "    - df_neigh: the dataframe containing the neighborhood of the cleavage site\n",
    "    - df_random: the dataframe containing random sequences\n",
    "    - test_size: the proportion of the testing set\n",
    "    - random_state: the random state\n",
    "    ### Returns:\n",
    "    - the training and testing sets\n",
    "    '''\n",
    "    #concatenate the two dataframes\n",
    "    df = pd.concat([df_neigh, df_random])\n",
    "    #split the dataframe into a training and a testing set\n",
    "    df_vectors = fsl.convert_df_to_vectors(df)\n",
    "\n",
    "    X = np.array(df_vectors['P_Structure_vector'].tolist())\n",
    "    y = np.array(df_vectors['cleavage'].tolist())\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_test_split_full(df, p, q, test_size = 0.2, random_state = 42, nb_neg = 2):\n",
    "    '''\n",
    "    split the dataframe into a training and a testing set\n",
    "    ### Parameters:\n",
    "    - df: the dataframe containing the neighborhood of the cleavage site\n",
    "    - test_size: the proportion of the testing set\n",
    "    - random_state: the random state\n",
    "    ### Returns:\n",
    "    - the training and testing sets\n",
    "    '''\n",
    "    df_neigh = extract_neighboorhood(df, p, q)\n",
    "    df_random = extract_random_sequence(df, p, q)\n",
    "    for i in range(nb_neg-1):\n",
    "        df_random = pd.concat([df_random, extract_random_sequence(df, p, q)])\n",
    "    return train_test_split2(df_neigh, df_random, test_size, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(svm_model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Assuming X_train and in_train have been defined as your features and target variable respectively\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for inclusion model:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\rabas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rabas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rabas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rabas\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rabas\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\rabas\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\rabas\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rabas\\anaconda3\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\rabas\\anaconda3\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']  # Different types of kernels\n",
    "}\n",
    "X_train, X_test, y_train, y_test = train_test_split_full(df, p=2, q=13, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "svm_model = svm.SVC(random_state=42, class_weight='balanced')  # Using balanced class weights\n",
    "\n",
    "# Setup the GridSearchCV\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='f1', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Assuming X_train and in_train have been defined as your features and target variable respectively\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters for inclusion model:\", grid_search.best_params_)\n",
    "print(\"Best score for inclusion model:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006392045454545455\n"
     ]
    }
   ],
   "source": [
    "# Parcourir la chaine de caractère pour trouver le cleavage site avec le modèle et le max de séparation\n",
    "def find_cleavage (X, svm_model, p:int = 2, q:int = 13, nb_letters = 26):\n",
    "    '''\n",
    "    find the position of the cleavage site in the primary structure using two SVM models\n",
    "    /!\\ the models must be trained before using this function with the same n and nb_letters as the ones used in this function\n",
    "    ### Parameters:\n",
    "    - X: the primary structure as a vector\n",
    "    - svm_model_in: the SVM model that predicts if the subsequence contains the cleavage site\n",
    "    - svm_model_pos: the SVM model that predicts the position of the cleavage site in the subsequence\n",
    "    - threshold: the threshold for the confidence of the prediction\n",
    "    ### Returns:\n",
    "    - the position of the cleavage site if the prediction is confident enough, otherwise Nan\n",
    "    '''\n",
    "    max_dist = 0\n",
    "    max_position = None\n",
    "    for i in range(p*nb_letters, len(X)- q*nb_letters, nb_letters):\n",
    "        test_sub = X[i-p*nb_letters :i + q*nb_letters]\n",
    "        \n",
    "        dist = svm_model.decision_function([test_sub])\n",
    "        if abs(dist) > max_dist:\n",
    "            max_dist = abs(dist)\n",
    "            max_position = i//nb_letters\n",
    "\n",
    "    return max_position if max_dist > 0  else None  # return None if no prediction is confident enough\n",
    "\n",
    "#test on all the dataframe\n",
    "def test_all(df, svm_model, p:int = 2, q:int = 13, nb_letters = 26):\n",
    "    '''\n",
    "    test the model on all the dataframe\n",
    "    ### Parameters:\n",
    "    - df: the dataframe containing the primary structure\n",
    "    - svm_model: the SVM model\n",
    "    - p: the number of amino acids before the cleavage site\n",
    "    - q: the number of amino acids after the cleavage site\n",
    "    - nb_letters: the number of amino acids in the alphabet\n",
    "    ### Returns:\n",
    "    - the dataframe with the predictions\n",
    "    '''\n",
    "    df_test = fsl.convert_df_to_vectors(df)\n",
    "    df_test['prediction'] = df_test['P_Structure_vector'].apply(lambda x: find_cleavage(x, svm_model, p, q, nb_letters))\n",
    "    accuracy_score = sum(df_test['position'] == df_test['prediction'])/df_test.shape[0]\n",
    "    return df_test, accuracy_score\n",
    "\n",
    "df_test, accuracy_score = test_all(df, best_model, p=2, q=13, nb_letters=26)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8633136094674556\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_full(df, p=2, q=13, test_size=0.2, random_state=42,nb_neg=5)\n",
    "best_model.fit(X_train, y_train)\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, best_model.predict(X_test))\n",
    "\n",
    "print(\"score\" , best_model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of predicted cleavage sites in the neighborhood: 0.9360795454545454\n",
      "Frequency of predicted cleavage sites in random sequences: 0.10582386363636363\n"
     ]
    }
   ],
   "source": [
    "df_neigh = extract_neighboorhood(df, p=2, q=13, nb_letters=26)\n",
    "df_neigh = fsl.convert_df_to_vectors(df_neigh)\n",
    "\n",
    "predict = best_model.predict(df_neigh['P_Structure_vector'].tolist())\n",
    "print(\"Frequency of predicted cleavage sites in the neighborhood:\", sum(predict)/len(predict))\n",
    "\n",
    "df_random = extract_random_sequence(df, p=2, q=13)\n",
    "df_random = fsl.convert_df_to_vectors(df_random)\n",
    "\n",
    "predict_random = best_model.predict(df_random['P_Structure_vector'].tolist())\n",
    "print(\"Frequency of predicted cleavage sites in random sequences:\", sum(predict_random)/len(predict_random))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
