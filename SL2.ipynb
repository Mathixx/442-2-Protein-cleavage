{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### MODULES NECESSAIRES ###\n",
    "###########################\n",
    "\n",
    "\n",
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import fonctionsSupervisedLearning2 as fsl2\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "\n",
    "from auxFonctions import AminoAcid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from a file into a list of entries\n",
    "with open('data/SIG_13.red', 'r') as file:\n",
    "    entries = file.read().split('\\n   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## RECUPERATION DES DONNÉES ##\n",
    "##############################\n",
    "\n",
    "# Process each entry\n",
    "processed_entries = [fsl2.process_entry(entry) for entry in entries]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(processed_entries)\n",
    "\n",
    "# Get the position of the cleavage site\n",
    "cleavage_site_position = df['Annotation'].apply(lambda x: x.find('C'))\n",
    "\n",
    "# Split the primary structure into a list of amino acids\n",
    "amino_acid_seq = df['Primary Structure'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put words in vector and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploitable = fsl2.convert_df_to_vectors2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "p,q = 13, 2  # p+q = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store, for each primary structure, the neihborhood of the cleavage site\n",
    "# The neighborhood is defined as the word of length p+q starting p letters before the cleavage site\n",
    "correct_neighborhood = pd.Series()\n",
    "for i, seq in amino_acid_seq.items():\n",
    "    correct_neighborhood[i] = ''.join(seq[cleavage_site_position[i]-p:cleavage_site_position[i]+q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store, for each primary structure, a sequence that is not the neighborhood of the cleavage site\n",
    "incorrect_neighborhood = pd.Series()\n",
    "decalage  = [1,2,3,4,5, -1,-2,-3,-4, -5]\n",
    "for i, seq in amino_acid_seq.items():\n",
    "    dec = np.random.choice(decalage)\n",
    "    dec = 0 if cleavage_site_position[i]-13 - dec < 0 else dec\n",
    "    incorrect_neighborhood[i] = ''.join(seq[cleavage_site_position[i]-p-dec:cleavage_site_position[i]+q-dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#print(correct_neighborhood.get(4))\n",
    "print(fsl2.word_to_vector(incorrect_neighborhood.get(52)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_random_subsequence2() missing 1 required positional argument: 'row'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, bool_train, bool_test \u001b[38;5;241m=\u001b[39m \u001b[43mfsl2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_train_split_random_pos2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_exploitable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m count_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m count_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/442-2-Protein-cleavage/fonctionsSupervisedLearning2.py:115\u001b[0m, in \u001b[0;36mtest_train_split_random_pos2\u001b[0;34m(df, n, p, test_size, random_state)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_train_split_random_pos2\u001b[39m(df, n , p,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m):\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    ### Parameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    - pos_test: the position of the cleavage site in the testing set\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     df_random \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[43mextract_random_subsequence2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n\u001b[38;5;241m=\u001b[39mn)\n\u001b[1;32m    116\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df_random[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_Structure_vector\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m    117\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df_random[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeighborhood_bool\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[0;31mTypeError\u001b[0m: extract_random_subsequence2() missing 1 required positional argument: 'row'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, bool_train, bool_test = fsl2.test_train_split_random_pos2(df_exploitable, 15, 13, random_state=42)\n",
    "\n",
    "count_true = 0\n",
    "count_all = 0\n",
    "for t in bool_train:\n",
    "    count_all += 1\n",
    "    if t:\n",
    "        count_true += 1\n",
    "\n",
    "print(count_true)\n",
    "print(count_all)\n",
    "print(bool_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1408,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     dec \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cleavage_site_position[i]\u001b[38;5;241m-\u001b[39mp \u001b[38;5;241m-\u001b[39m dec \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m dec\n\u001b[1;32m     24\u001b[0m     incorrect_neighborhood[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(seq[cleavage_site_position[i]\u001b[38;5;241m-\u001b[39mp\u001b[38;5;241m-\u001b[39mdec:cleavage_site_position[i]\u001b[38;5;241m+\u001b[39mq\u001b[38;5;241m-\u001b[39mdec])\n\u001b[0;32m---> 26\u001b[0m svm_model_nei, accuracy_nei \u001b[38;5;241m=\u001b[39m \u001b[43mfsl2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_exploitable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_nei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_nei\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m count_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(correct_neighborhood)):\n",
      "File \u001b[0;32m~/Documents/GitHub/442-2-Protein-cleavage/fonctionsSupervisedLearning2.py:176\u001b[0m, in \u001b[0;36mcreate_model2\u001b[0;34m(n, p, df_exploitable, kernel_neighbor, C_nei, random_state, nb_letters)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model2\u001b[39m(n, p, df_exploitable, kernel_neighbor, C_nei, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, nb_letters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m26\u001b[39m):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    Create a model that predicts the position of the cleavage site in a primary structure\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    ### Parameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m \n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     X_train, X_test, bool_train, bool_test \u001b[38;5;241m=\u001b[39m \u001b[43mtest_train_split_random_pos2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_exploitable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m#in_train = ~np.isnan(bool_train)\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m#in_test = ~np.isnan(bool_test)\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     svm_model_neighbor \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(kernel\u001b[38;5;241m=\u001b[39mkernel_neighbor, C\u001b[38;5;241m=\u001b[39mC_nei, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/Documents/GitHub/442-2-Protein-cleavage/fonctionsSupervisedLearning2.py:116\u001b[0m, in \u001b[0;36mtest_train_split_random_pos2\u001b[0;34m(df, n, p, test_size, random_state)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03mSplit the data into training and testing sets\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m### Parameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m- pos_test: the position of the cleavage site in the testing set\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    115\u001b[0m df_random \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(extract_random_subsequence2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n\u001b[38;5;241m=\u001b[39mn, p \u001b[38;5;241m=\u001b[39m p)\n\u001b[0;32m--> 116\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_random\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mP_Structure_vector\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df_random[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeighborhood_bool\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m    118\u001b[0m X_train, X_test, bool_train, bool_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39mtest_size, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1408,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "#svm_model_nei, accuracy_nei = fsl2.create_model2(15, df_exploitable, random_state=42, nb_letters = 26, kernel_neighbor= 'rbf',C_nei = 1)\n",
    "\n",
    "\n",
    "C_list = [0.1,1,2, 5]\n",
    "kernel_list = ['linear', 'rbf', 'sigmoid', 'poly']\n",
    "p_list = [3, 5, 7, 9, 11, 13, 15]\n",
    "q_list = [2, 4, 6, 8]\n",
    "results = []\n",
    "\n",
    "for C_nei in C_list:\n",
    "    for kernel_nei in kernel_list:\n",
    "        for p in p_list:\n",
    "            for q in q_list:\n",
    "                n = p+q\n",
    "                correct_neighborhood = pd.Series()\n",
    "                for i, seq in amino_acid_seq.items():   \n",
    "                    correct_neighborhood[i] = ''.join(seq[cleavage_site_position[i]-p:cleavage_site_position[i]+q])\n",
    "\n",
    "                incorrect_neighborhood = pd.Series()\n",
    "                decalage  = [1,2,3,4,5, -1,-2,-3,-4, -5]\n",
    "                for i, seq in amino_acid_seq.items():\n",
    "                    dec = np.random.choice(decalage)\n",
    "                    dec = 0 if cleavage_site_position[i]-p - dec < 0 else dec\n",
    "                    incorrect_neighborhood[i] = ''.join(seq[cleavage_site_position[i]-p-dec:cleavage_site_position[i]+q-dec])\n",
    "\n",
    "                svm_model_nei, accuracy_nei = fsl2.create_model2(n, p, df_exploitable, kernel_nei, C_nei)\n",
    "\n",
    "                count_fn = 0\n",
    "                for i in range(0, len(correct_neighborhood)):\n",
    "                    x = np.array([fsl2.word_to_vector(correct_neighborhood.get(i))])\n",
    "                    test = svm_model_nei.predict(x)\n",
    "                    if (test == 0):\n",
    "                        count_fn += 1\n",
    "                count_fp = 0\n",
    "                for i in range(0, len(incorrect_neighborhood)):\n",
    "                    x = np.array([fsl2.word_to_vector(incorrect_neighborhood.get(i))])\n",
    "                    test = svm_model_nei.predict(x)\n",
    "                    if (test == 1):\n",
    "                        count_fp += 1\n",
    "            \n",
    "                results.append((C_nei, kernel_nei, p, q, accuracy_nei, count_fn/len(correct_neighborhood), count_fp/len(incorrect_neighborhood)))\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['C','Kernel', 'p', 'q', 'Accuracy', 'False negative rate', 'False positive rate'])\n",
    "results_df.to_csv('results2.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C                           0.1\n",
      "Kernel                  sigmoid\n",
      "p                             9\n",
      "q                             4\n",
      "Accuracy               0.897163\n",
      "False negative rate    0.180398\n",
      "False positive rate    0.244318\n",
      "Name: 61, dtype: object\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.read_csv('results2.csv', index_col=0)\n",
    "\n",
    "best_results = results_df.loc[(results_df['Accuracy']).idxmax()]\n",
    "print(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from CSV\n",
    "results_df = pd.read_csv('results2.csv')\n",
    "\n",
    "# Setting the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a series of plots\n",
    "def plot_results(data, x, y, hue, col=None, kind='line', col_wrap=4, height=3):\n",
    "    \"\"\"\n",
    "    A function to create a FacetGrid plot for the specified parameters.\n",
    "    \"\"\"\n",
    "    g = sns.relplot(\n",
    "        data=data,\n",
    "        x=x, y=y, hue=hue, \n",
    "        col=col, col_wrap=col_wrap,\n",
    "        kind=kind,\n",
    "        height=height,\n",
    "        facet_kws={'sharey': False, 'sharex': False}\n",
    "    )\n",
    "    g.set_axis_labels(x, f\"{y} Rate\")\n",
    "    g.set_titles(\"{col_name}\")\n",
    "    g.add_legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy by C parameter for each kernel type\n",
    "plot_results(results_df, x='C_nei', y='accuracy_nei', hue='kernel_nei', col='kernel_nei', kind='line')\n",
    "\n",
    "# Plot false negative rate by C parameter for each kernel type\n",
    "plot_results(results_df, x='C_nei', y='false negative', hue='kernel_nei', col='kernel_nei', kind='line')\n",
    "\n",
    "# Plot false positive rate by C parameter for each kernel type\n",
    "plot_results(results_df, x='C_nei', y='false positive', hue='kernel_nei', col='kernel_nei', kind='line')\n",
    "\n",
    "# Additional plots can be created for other relationships\n",
    "# For example, how the accuracy changes with p and q\n",
    "plot_results(results_df, x='p', y='accuracy_nei', hue='q', col='kernel_nei', kind='line', col_wrap=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_nei, accuracy_nei = fsl2.create_model2(15, df_exploitable,'rbf', 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8687943262411347\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_nei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(0, len(correct_neighborhood)):\n",
    "    X = fsl2.word_to_vector(df[\"Primary Structure\"].get(i))\n",
    "    if fsl2.find_cleavage2(X,svm_model_nei,15):\n",
    "        count += 1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de faux négatifs :126\n",
      "Nombre de faux positifs :460\n",
      "Nombre total :1408\n"
     ]
    }
   ],
   "source": [
    "count_fn = 0\n",
    "for i in range(0, len(correct_neighborhood)):\n",
    "    test = fsl2.is_neighborhood2(correct_neighborhood.get(i), svm_model_nei, 15)\n",
    "    if not(test):\n",
    "        count_fn += 1\n",
    "\n",
    "print(\"Nombre de faux négatifs :\" + str(count_fn))\n",
    "\n",
    "count_fp = 0\n",
    "for i in range(0, len(incorrect_neighborhood)):\n",
    "    try : \n",
    "        test = fsl2.is_neighborhood2(incorrect_neighborhood.get(i), svm_model_nei, 15)\n",
    "        if test:\n",
    "            count_fp += 1\n",
    "    except:\n",
    "        print(\"Erreur\" + str(i))\n",
    "        #print(incorrect_neighborhood.get(i))\n",
    "\n",
    "\n",
    "print(\"Nombre de faux positifs :\" + str(count_fp))\n",
    "print(\"Nombre total :\" + str(len(correct_neighborhood)))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
